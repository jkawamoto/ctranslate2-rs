[package]
name = "ct2rs"
version.workspace = true
authors.workspace = true
categories = ["api-bindings"]
documentation = "https://docs.rs/ct2rs"
edition.workspace = true
include = [
    "/include",
    "/src",
    "/build.rs",
    "/LICENSE",
    "/examples",
    "/CTranslate2/CMakeLists.txt",
    "/CTranslate2/LICENSE",
    "/CTranslate2/cmake",
    "/CTranslate2/cpp",
    "/CTranslate2/include",
    "/CTranslate2/python",
    "/CTranslate2/src",
    "/CTranslate2/third_party",
    "!/CTranslate2/**/.*",
    "!/CTranslate2/**/test",
    "!/CTranslate2/**/docs",
    "!/CTranslate2/**/media",
]
keywords = ["ctranslate2", "bindings", "llm", "whisper"]
license.workspace = true
readme = "../README.md"
repository.workspace = true
description = "Rust bindings for OpenNMT/CTranslate2"

[dependencies]
anyhow = "1.0.98"
cxx = { version = "1.0", features = ["c++17"] }
intel-onemkl-prebuild = { version = "0.1", optional = true }
onednn-src = { version = "0.1", optional = true }
sentencepiece = { version = "0.11.3", optional = true }
tokenizers = { version = "0.21", optional = true }

# Dependencies for Whisper model
mel_spec = { version = "0.3", optional = true }
ndarray = { version = "0.16.1", optional = true }
serde = { version = "1.0.219", features = ["derive"], optional = true }
serde_json = { version = "1.0", optional = true }

# Dependencies for Hugging Face integration
hf-hub = { version = "0.4", optional = true }

[dev-dependencies]
clap = { version = "4.5", features = ["derive"] }
rand = "0.9.1"

# Dependencies for Whisper example
hound = { version = "3.5.1" }

[build-dependencies]
cmake = "0.1.54"
cxx-build = "1.0"
walkdir = "2.5.0"

[features]
default = ["all-tokenizers", "ruy", "cuda-small-binary"]
whisper = [
    "dep:mel_spec",
    "dep:ndarray",
    "dep:serde",
    "dep:serde_json",
    "all-tokenizers",
]
hub = ["dep:hf-hub"]

# Features to select backends.
cuda = []
cudnn = ["cuda"]
mkl = ["dep:intel-onemkl-prebuild"]
openblas = []
dnnl = ["dep:onednn-src"]
ruy = []
accelerate = []
openmp-runtime-comp = []
openmp-runtime-intel = []
msse4_1 = []

# Features to enable GPU functionality.
flash-attention = []
tensor-parallel = []
cuda-dynamic-loading = ["cuda"]
cuda-small-binary = []

# Futures to select tokenizers.
all-tokenizers = ["sentencepiece", "tokenizers"]
sentencepiece = ["dep:sentencepiece"]
tokenizers = ["dep:tokenizers"]

[[example]]
name = "bart"

[[example]]
name = "bloom"

[[example]]
name = "falcon"

[[example]]
name = "marian-mt"

[[example]]
name = "mpt"

[[example]]
name = "nllb"

[[example]]
name = "gpt-2"

[[example]]
name = "gpt-j"

[[example]]
name = "gpt-neox"

[[example]]
name = "opt"
required-features = ["tokenizers"]

[[example]]
name = "t5"

[[example]]
name = "stream"

[[example]]
name = "whisper"
required-features = ["whisper"]

[package.metadata.docs.rs]
features = ["whisper", "hub"]
